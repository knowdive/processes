<?xml version="1.0" encoding="UTF-8"?><process version="9.2.001">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.2.001" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="false" class="read_excel" compatibility="9.2.001" expanded="true" height="68" name="Read Knowledge" width="90" x="313" y="34">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\Internship\KnowDive\resources\KnowledgeFull.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information"/>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
      </operator>
      <operator activated="false" class="read_excel" compatibility="9.2.001" expanded="true" height="68" name="Read Knowledge (2)" width="90" x="313" y="187">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\Internship\KnowDive\resources\KnowledgeFull.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information"/>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
      </operator>
      <operator activated="true" class="read_excel" compatibility="9.2.001" expanded="true" height="68" name="Read Knowledge (3)" width="90" x="313" y="340">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\Internship\KnowDive\resources\KnowledgeFull.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information"/>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
      </operator>
      <operator activated="false" class="read_excel" compatibility="9.2.001" expanded="true" height="68" name="Read Predicates" width="90" x="179" y="85">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\Internship\InternshipCode\RapidMinerCode\knowledgeFilter\Predicate.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information"/>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
      </operator>
      <operator activated="false" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="124" name="KnowledgeParser_Full" width="90" x="514" y="34">
        <parameter key="script" value="# Import libraries&#10;import rdflib&#10;from rdflib import Graph, Namespace&#10;from rdflib.util import guess_format&#10;from rdflib.plugins.parsers.notation3 import N3Parser&#10;import pandas as pd&#10;import os&#10;import time&#10;&#10;# Class to handle the Excel file and relative indexes&#10;class ExcelFile:&#10;    def __init__(self, writer, num = 0):&#10;        self.writer = writer&#10;        self.index = 1&#10;        self.num = num + 1&#10;&#10;# Parse the given file and add its information to the file Excel given as third parameter&#10;def parse(vocabFolder, date, row, totalExcel, list_, predicates):&#10;    # Try to create the graph to analyze the vocabulary&#10;    try:&#10;        g = Graph()&#10;        format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-1]&#10;        if(format_ == &quot;txt&quot;):&#10;            format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-2]&#10;        format_ = format_.split(&quot;?&quot;)[0]&#10;        result = g.parse(row[&quot;Link&quot;], format=guess_format(format_), publicID=row[&quot;prefix&quot;])&#10;    except Exception as e:&#10;        # In case of an error during the graph's initiation, print the error and return an empty list&#10;        print(str(e) + &quot;\n&quot;)    &#10;        return totalExcel, list_, 0&#10;&#10;    # Serialize the vocabulary in multiple formats&#10;    serializedName = date + &quot;_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;] + &quot;.&quot;&#10;    serializeVoc(vocabFolder, serializedName + &quot;n3&quot;, g, &quot;n3&quot;)&#10;    serializeVoc(vocabFolder, serializedName + &quot;nt&quot;, g, &quot;nt&quot;)&#10;    serializeVoc(vocabFolder, serializedName + &quot;rdf&quot;, g, &quot;pretty-xml&quot;)&#10;    serializeVoc(vocabFolder, serializedName + &quot;ttl&quot;, g, &quot;turtle&quot;)&#10;    serializeVoc(vocabFolder, serializedName + &quot;json-ld&quot;, g, &quot;json-ld&quot;)&#10;&#10;    print(row[&quot;prefix&quot;])&#10;&#10;    # Get the totalExcel file and relative worksheets&#10;    totalWorkbook = totalExcel.writer.book&#10;    totalFullSheet = totalWorkbook.get_worksheet_by_name(&quot;Total Full Triples&quot;)&#10;&#10;    # Elaborate the fileName of the vocabulary&#10;    fileName = date + &quot;_Full_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;] + &quot;_&quot;&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    singleExcel, singleWorkbook, singleFullSheet = newExcel(0, str(os.path.join(vocabFolder, fileName + &quot;_0.xlsx&quot;)), &quot;Single Full Triples&quot;)&#10;&#10;    # For each statement present in the graph obtained store the triples&#10;    index = 0&#10;    for subject, predicate, object_ in g:&#10;        # Compute the filtered statement of the Triples&#10;        predicateTerm = predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;        if(not len(predicateTerm) and len(predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)) &gt; 1):&#10;            predicateTerm = predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-2]&#10;        if(row[&quot;prefix&quot;] == &quot;FreeBase&quot;):&#10;            predicateTerm = predicateTerm.split(&quot;.&quot;)[-1]&#10;            if(not len(objectTerm) and len(predicateTerm.split(&quot;.&quot;)) &gt; 1):&#10;                predicateTerm = predicateTerm.split(&quot;.&quot;)[-2]&#10;&#10;        # Check if the triple has to be saved, if there is a predicate selection then checks if that predicate has to be saved&#10;        bool_ = False&#10;        # If there is no predicate selection then save every triple&#10;        if(len(predicates) == 0):&#10;            bool_ = True&#10;        # If there is a predicate selection then check if that predicate has to be saved&#10;        else:&#10;            for pred in predicates[&quot;Predicate&quot;]:&#10;                if(pred == str(predicateTerm) or pred == str(predicate)):&#10;                    bool_ = True&#10;                    break&#10;        # Check if the triple has to be saved&#10;        if(bool_ == True):&#10;            # Save the full statement to the ExcelSheet FullTriples&#10;            singleFullSheet.write_row(singleExcel.index, 0, (date, subject, predicate, object_, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;            totalFullSheet.write_row(totalExcel.index, 0, (date, subject, predicate, object_, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;            # Update the index of both the ExcelFiles&#10;            singleExcel.index += 1&#10;            totalExcel.index += 1&#10;            # Save the Full statement to the List to be added to the DataFrame&#10;            list_.insert(index,{&quot;Date&quot;: date, &quot;Subject&quot;: subject, &quot;Predicate&quot;: predicate, &quot;Object&quot;: object_, &quot;Domain&quot;: row[&quot;prefix&quot;], &quot;Domain Version&quot;: row[&quot;VersionName&quot;], &quot;Domain Date&quot;: row[&quot;VersionDate&quot;], &quot;URI&quot;: row[&quot;URI&quot;], &quot;Title&quot;: row[&quot;Title&quot;], &quot;Languages&quot;: row[&quot;Languages&quot;]})&#10;            index += 1&#10;&#10;            # If the rows reach the excel limit then create a new ExcelFile&#10;            if(singleExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                singleWorkbook.close()&#10;                singleExcel.writer.save()&#10;                # Create a new ExcelFile&#10;                singleExcel, singleWorkbook, singleFullSheet = newExcel(singleExcel.num, str(os.path.join(vocabFolder, fileName + str(singleExcel.num) + &quot;.xlsx&quot;)), &quot;Single Full Triples&quot;)&#10;            # If the rows reach the excel limit then create a new ExcelFile&#10;            if(totalExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                totalExcel.writer.book.close()&#10;                totalExcel.writer.save()&#10;                # Create a new ExcelFile&#10;                totalExcel, totalWorkbook, totalFullSheet = newExcel(totalExcel.num, str(os.path.join(os.path.dirname(vocabFolder), date + &quot;_Full_Knowledge-Triples_&quot; + str(totalExcel.num) + &quot;.xlsx&quot;)), &quot;Total Full Triples&quot;)&#10;&#10;    # Close the Excel file of the single vocabulary&#10;    singleExcel.writer.book.close()&#10;    singleExcel.writer.save()&#10;&#10;    # Return the List to be added to the DataFrame and the relative index&#10;    return totalExcel, list_, index&#10;&#10;# Serialize the vocabulary in a format saved in vocabFolder/Resources with the same name of the Excel File&#10;def serializeVoc(vocabFolder, fileName, g, format_):&#10;    try:&#10;        resourceDestination = os.path.join(vocabFolder, &quot;Resources/&quot;+format_)&#10;        if not os.path.isdir(resourceDestination):&#10;            os.makedirs(resourceDestination)&#10;        g.serialize(destination=str(os.path.join(resourceDestination, fileName)), format=format_)&#10;    except Exception as e:&#10;        # In case of an error during the graph's serialization, print the error&#10;        print(str(e) + &quot;\n&quot;)&#10;&#10;# Create a new ExcelFile&#10;def newExcel(excelNum, fileName, sheetName):&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    writer = pd.ExcelWriter(fileName, engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;    excelFile_ = ExcelFile(writer, excelNum)&#10;    # Get the xlsxwriter workbook and worksheet objects.&#10;    workbook  = writer.book&#10;    # Add WorkSheet with relative titles and relative bold header &#10;    worksheet = workbook.add_worksheet(sheetName)&#10;    worksheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), workbook.add_format({&quot;bold&quot;: True}))&#10;    worksheet.set_column(0, 8, 30)&#10;    # Return the new excelFile_, workbook, worksheet&#10;    return excelFile_, workbook, worksheet&#10;&#10;# Mandatory function for RapidMiner&#10;def rm_main(vocabs, predicates = pd.DataFrame()):&#10;    # Create the folder used to store the results&#10;    location = os.path.normpath(os.path.expanduser(&quot;~/Desktop/K-Files/&quot;))&#10;    if not os.path.isdir(location):&#10;        os.makedirs(location)&#10;&#10;    # Get the date of the current day of the Parsing&#10;    date = time.strftime(&quot;%Y-%m-%d&quot;, time.gmtime())&#10;&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    totalExcel, totalWorkbook, totalFullSheet = newExcel(0, str(os.path.join(location, date + &quot;_Full_Knowledge-Triples_0.xlsx&quot;)), &quot;Total Full Triples&quot;)&#10;&#10;    # Create the DataFrame to save the vocabs' Date of parsing, Subject, Predicate, Object, Domain, Domain Version, Domain Date, URI, Title, Languages&#10;    df = pd.DataFrame(columns=[&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;])&#10;&#10;    # Iterate for every vocabulary read from the second argument&#10;    for index, row in vocabs.iterrows():&#10;        # Create the Folder &#10;        vocabFolder = str(os.path.join(location, row[&quot;Folder&quot;]))&#10;        if not os.path.isdir(vocabFolder):&#10;            os.makedirs(vocabFolder)&#10;        &#10;        # Add information for each vocabulary&#10;        totalExcel, list_, i = parse(vocabFolder, date, row, totalExcel, list(), predicates)&#10;        # Save the information on the DataFrame for each vocabulary&#10;        if(i and len(list_)):&#10;            df = df.append(list_)&#10;&#10;    # Close the Excel file of the single vocabulary&#10;    totalExcel.writer.book.close()&#10;    totalExcel.writer.save()&#10;&#10;    # Return the DataFrame for RapidMiner visualization&#10;    return df"/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
      </operator>
      <operator activated="false" class="write_csv" compatibility="9.2.001" expanded="true" height="82" name="Write CSV Full" width="90" x="782" y="34">
        <parameter key="csv_file" value="C:\Users\marco\Desktop\K-Files\FullTriples.csv"/>
        <parameter key="column_separator" value="|"/>
        <parameter key="write_attribute_names" value="true"/>
        <parameter key="quote_nominal_values" value="true"/>
        <parameter key="format_date_attributes" value="true"/>
        <parameter key="append_to_file" value="false"/>
        <parameter key="encoding" value="SYSTEM"/>
      </operator>
      <operator activated="false" class="read_excel" compatibility="9.2.001" expanded="true" height="68" name="Read Predicates (2)" width="90" x="179" y="238">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\Internship\InternshipCode\RapidMinerCode\knowledgeFilter\Predicate.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information"/>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
      </operator>
      <operator activated="false" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="124" name="KnowledgeParser_Filtered" width="90" x="514" y="187">
        <parameter key="script" value="# Import libraries&#10;import rdflib&#10;from rdflib import Graph, Namespace&#10;from rdflib.util import guess_format&#10;from rdflib.plugins.parsers.notation3 import N3Parser&#10;import pandas as pd&#10;import os&#10;import time&#10;&#10;# Class to handle the Excel file and relative indexes&#10;class ExcelFile:&#10;    def __init__(self, writer, num = 0):&#10;        self.writer = writer&#10;        self.index = 1&#10;        self.num = num + 1&#10;&#10;# Parse the given file and add its information to the file Excel given as third parameter&#10;def parse(vocabFolder, date, row, totalExcel, list_, predicates):&#10;    # Try to create the graph to analyze the vocabulary&#10;    try:&#10;        g = Graph()&#10;        format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-1]&#10;        if(format_ == &quot;txt&quot;):&#10;            format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-2]&#10;        format_ = format_.split(&quot;?&quot;)[0]&#10;        result = g.parse(row[&quot;Link&quot;], format=guess_format(format_), publicID=row[&quot;prefix&quot;])&#10;    except Exception as e:&#10;        # In case of an error during the graph's initiation, print the error and return an empty list&#10;        print(str(e) + &quot;\n&quot;)    &#10;        return totalExcel, list_, 0&#10;&#10;    # Serialize the vocabulary in multiple formats&#10;    serializedName = date + &quot;_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;] + &quot;.&quot;&#10;    serializeVoc(vocabFolder, serializedName + &quot;n3&quot;, g, &quot;n3&quot;)&#10;    serializeVoc(vocabFolder, serializedName + &quot;nt&quot;, g, &quot;nt&quot;)&#10;    serializeVoc(vocabFolder, serializedName + &quot;rdf&quot;, g, &quot;pretty-xml&quot;)&#10;    serializeVoc(vocabFolder, serializedName + &quot;ttl&quot;, g, &quot;turtle&quot;)&#10;    serializeVoc(vocabFolder, serializedName + &quot;json-ld&quot;, g, &quot;json-ld&quot;)&#10;&#10;    print(row[&quot;prefix&quot;])&#10;&#10;    # Get the totalExcel file and relative worksheets&#10;    totalWorkbook = totalExcel.writer.book&#10;    totalFilteredSheet = totalWorkbook.get_worksheet_by_name(&quot;Total Filtered Triples&quot;)&#10;&#10;    # Elaborate the fileName of the vocabulary&#10;    fileName = date + &quot;_Filtered_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;] + &quot;_&quot;&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    singleExcel, singleWorkbook, singleFilteredSheet = newExcel(0, str(os.path.join(vocabFolder, fileName + &quot;0.xlsx&quot;)), &quot;Single Filtered Triples&quot;)&#10;&#10;    # For each statement present in the graph obtained store the triples&#10;    index = 0&#10;    for subject, predicate, object_ in g:&#10;        # Compute the filtered statement of the Triples&#10;        subjectTerm = subject.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;        if(not len(subjectTerm) and len(subject.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)) &gt; 1):&#10;            subjectTerm = subject.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-2]&#10;        predicateTerm = predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;        if(not len(predicateTerm) and len(predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)) &gt; 1):&#10;            predicateTerm = predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-2]&#10;        objectTerm = object_.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;        if(not len(objectTerm) and len(object_.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)) &gt; 1):&#10;            objectTerm = object_.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-2]&#10;        if(row[&quot;prefix&quot;] == &quot;FreeBase&quot;):&#10;            subjectTerm = subjectTerm.split(&quot;.&quot;)[-1]&#10;            if(not len(subjectTerm) and len(subjectTerm.split(&quot;.&quot;)) &gt; 1):&#10;                subjectTerm = subjectTerm.split(&quot;.&quot;)[-2]&#10;            predicateTerm = predicateTerm.split(&quot;.&quot;)[-1]&#10;            if(not len(objectTerm) and len(predicateTerm.split(&quot;.&quot;)) &gt; 1):&#10;                predicateTerm = predicateTerm.split(&quot;.&quot;)[-2]&#10;            objectTerm = objectTerm.split(&quot;.&quot;)[-1]&#10;            if(not len(objectTerm) and len(objectTerm.split(&quot;.&quot;)) &gt; 1):&#10;                objectTerm = objectTerm.split(&quot;.&quot;)[-2]&#10;&#10;        # Check if the triple has to be saved, if there is a predicate selection then checks if that predicate has to be saved&#10;        bool_ = False&#10;        # If there is no predicate selection then save every triple&#10;        if(len(predicates) == 0):&#10;            bool_ = True&#10;        # If there is a predicate selection then check if that predicate has to be saved&#10;        else:&#10;            for pred in predicates[&quot;Predicate&quot;]:&#10;                if(pred == str(predicateTerm) or pred == str(predicate)):&#10;                    bool_ = True&#10;                    break&#10;        # Check if the triple has to be saved&#10;        if(bool_ == True):&#10;            # Save the Filtered statement to the List to be added to the DataFrame&#10;            list_.insert(index,{&quot;Date&quot;: date, &quot;Subject&quot;: subjectTerm, &quot;Predicate&quot;: predicateTerm, &quot;Object&quot;: objectTerm, &quot;Domain&quot;: row[&quot;prefix&quot;], &quot;Domain Version&quot;: row[&quot;VersionName&quot;], &quot;Domain Date&quot;: row[&quot;VersionDate&quot;], &quot;URI&quot;: row[&quot;URI&quot;], &quot;Title&quot;: row[&quot;Title&quot;], &quot;Languages&quot;: row[&quot;Languages&quot;]})&#10;            index += 1&#10;            # Save the Filtered statement to the ExcelSheet FilteredTriples&#10;            singleFilteredSheet.write_row(singleExcel.index, 0, (date, subjectTerm, predicateTerm, objectTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;            totalFilteredSheet.write_row(totalExcel.index, 0, (date, subjectTerm, predicateTerm, objectTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;            # Update the index of both the ExcelFiles&#10;            singleExcel.index += 1&#10;            totalExcel.index += 1&#10;            # If the rows reach the excel limit then create a new ExcelFile&#10;            if(singleExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                singleWorkbook.close()&#10;                singleExcel.writer.save()&#10;                # Create a new ExcelFile&#10;                singleExcel, singleWorkbook, singleFilteredSheet = newExcel(singleExcel.num, str(os.path.join(vocabFolder, fileName + str(singleExcel.num) + &quot;.xlsx&quot;)), &quot;Single Filtered Triples&quot;)&#10;            # If the rows reach the excel limit then create a new ExcelFile&#10;            if(totalExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                totalExcel.writer.book.close()&#10;                totalExcel.writer.save()&#10;                # Create a new ExcelFile&#10;                totalExcel, totalWorkbook, totalFilteredSheet = newExcel(totalExcel.num, str(os.path.join(os.path.dirname(vocabFolder), date + &quot;_Filtered_Knowledge-Triples_&quot; + str(totalExcel.num) + &quot;.xlsx&quot;)), &quot;Total Filtered Triples&quot;)&#10;&#10;    # Close the Excel file of the single vocabulary&#10;    singleExcel.writer.book.close()&#10;    singleExcel.writer.save()&#10;&#10;    # Return the List to be added to the DataFrame and the relative index&#10;    return totalExcel, list_, index&#10;&#10;# Serialize the vocabulary in a format saved in vocabFolder/Resources with the same name of the Excel File&#10;def serializeVoc(vocabFolder, fileName, g, format_):&#10;    try:&#10;        resourceDestination = os.path.join(vocabFolder, &quot;Resources/&quot;+format_)&#10;        if not os.path.isdir(resourceDestination):&#10;            os.makedirs(resourceDestination)&#10;        g.serialize(destination=str(os.path.join(resourceDestination, fileName)), format=format_)&#10;    except Exception as e:&#10;        # In case of an error during the graph's serialization, print the error&#10;        print(str(e) + &quot;\n&quot;)&#10;&#10;# Create a new ExcelFile&#10;def newExcel(excelNum, fileName, sheetName):&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    writer = pd.ExcelWriter(fileName, engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;    excelFile_ = ExcelFile(writer, excelNum)&#10;    # Get the xlsxwriter workbook and worksheet objects.&#10;    workbook  = writer.book&#10;    # Add WorkSheet with relative titles and relative bold header &#10;    worksheet = workbook.add_worksheet(sheetName)&#10;    worksheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), workbook.add_format({&quot;bold&quot;: True}))&#10;    worksheet.set_column(0, 8, 30)&#10;    # Return the new excelFile_, workbook, worksheet&#10;    return excelFile_, workbook, worksheet&#10;&#10;# Mandatory function for RapidMiner&#10;def rm_main(vocabs, predicates = pd.DataFrame()):&#10;    # Create the folder used to store the results&#10;    location = os.path.normpath(os.path.expanduser(&quot;~/Desktop/K-Files/&quot;))&#10;    if not os.path.isdir(location):&#10;        os.makedirs(location)&#10;&#10;    # Get the date of the current day of the Parsing&#10;    date = time.strftime(&quot;%Y-%m-%d&quot;, time.gmtime())&#10;&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    totalExcel, totalWorkbook, totalFilteredSheet = newExcel(0, str(os.path.join(location, date + &quot;_Filtered_Knowledge-Triples_0.xlsx&quot;)), &quot;Total Filtered Triples&quot;)&#10;&#10;    # Create the DataFrame to save the vocabs' Date of parsing, Subject, Predicate, Object, Domain, Domain Version, Domain Date, URI, Title, Languages&#10;    df = pd.DataFrame(columns=[&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;])&#10;&#10;    # Iterate for every vocabulary read from the second argument&#10;    for index, row in vocabs.iterrows():&#10;        # Create the Folder &#10;        vocabFolder = str(os.path.join(location, row[&quot;Folder&quot;]))&#10;        if not os.path.isdir(vocabFolder):&#10;            os.makedirs(vocabFolder)&#10;        &#10;        # Add information for each vocabulary&#10;        totalExcel, list_, i = parse(vocabFolder, date, row, totalExcel, list(), predicates)&#10;        # Save the information on the DataFrame for each vocabulary&#10;        if(i and len(list_)):&#10;            df = df.append(list_)&#10;&#10;    # Close the Excel file of the single vocabulary&#10;    totalExcel.writer.book.close()&#10;    totalExcel.writer.save()&#10;&#10;    # Return the DataFrame for RapidMiner visualization&#10;    return df"/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
      </operator>
      <operator activated="false" class="write_csv" compatibility="9.2.001" expanded="true" height="82" name="Write CSV Filtered" width="90" x="782" y="187">
        <parameter key="csv_file" value="C:\Users\marco\Desktop\K-Files\FilteredTriples.csv"/>
        <parameter key="column_separator" value="|"/>
        <parameter key="write_attribute_names" value="true"/>
        <parameter key="quote_nominal_values" value="true"/>
        <parameter key="format_date_attributes" value="true"/>
        <parameter key="append_to_file" value="false"/>
        <parameter key="encoding" value="SYSTEM"/>
      </operator>
      <operator activated="true" class="read_excel" compatibility="9.2.001" expanded="true" height="68" name="Read Predicates (3)" width="90" x="179" y="391">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\Internship\InternshipCode\RapidMinerCode\knowledgeFilter\Predicate.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information"/>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="124" name="KnowledgeInheritor" width="90" x="514" y="340">
        <parameter key="script" value="# Import libraries&#10;import rdflib&#10;from rdflib import Graph, RDFS&#10;from rdflib.util import guess_format&#10;from rdflib.plugins.parsers.notation3 import N3Parser&#10;import pandas as pd&#10;import os&#10;import time&#10;import networkx as nx&#10;&#10;# Class to handle the Excel file and relative indexes&#10;class ExcelFile:&#10;    def __init__(self, writer, num = 0):&#10;        self.writer = writer&#10;        self.index = 1&#10;        self.num = num + 1&#10;&#10;# Parse the given file and add its information to the file Excel given as third parameter&#10;def parse(vocabFolder, date, row, inTotalExcel, list_, predicates):&#10;    # Try to create the graph to analyze the vocabulary&#10;    try:&#10;        g = Graph()&#10;        format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-1]&#10;        if(format_ == &quot;txt&quot;):&#10;            format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-2]&#10;        format_ = format_.split(&quot;?&quot;)[0]&#10;        result = g.parse(row[&quot;Link&quot;], format=guess_format(format_), publicID=row[&quot;prefix&quot;])&#10;    except Exception as e:&#10;        # In case of an error during the graph's initiation, print the error and return an empty list&#10;        print(str(e) + &quot;\n&quot;)    &#10;        return inTotalExcel, list_, 0&#10;&#10;    # Get the inTotalExcel file and relative worksheets&#10;    inTotalWorkbook = inTotalExcel.writer.book&#10;    inTotalSheet = inTotalWorkbook.get_worksheet_by_name(&quot;Inherited Total Triples&quot;)&#10;&#10;    # Elaborate the fileName of the vocabulary&#10;    inFileName = date + &quot;_Inherited_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;] + &quot;_&quot;&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    inSingleExcel, inSingleWorkbook, inSingleSheet = newExcel(0, str(os.path.join(vocabFolder, inFileName + &quot;0.xlsx&quot;)), &quot;Inherited Single Triples&quot;)&#10;&#10;    # Create the DataFrame used to save the table used to handle the inheritance relations&#10;    inherit = pd.DataFrame(columns=[&quot;Subject&quot;, &quot;subOf&quot;, &quot;subbed&quot;])&#10;    # Create the set used to check if new Subject inheritance relation has to be added or if existing Subject inheritance relation has to be updated&#10;    set_ = set()&#10;    # Save inheritance relation between subject and object&#10;    for s, o in g.subject_objects(RDFS.subClassOf):&#10;        inherit, set_ = setInheritance(str(s), str(o), inherit, set_)&#10;    # Create the networkx graph used to calculate inheritance&#10;    nxG = createNXGraph(inherit)&#10;    # Calculate the transitive_closure of the networkx graph to get all the possible inheritances&#10;    nxGT = nx.transitive_closure(nxG)&#10;&#10;    # For each statement present in the graph obtained store the triples&#10;    index = 0&#10;    for subject, predicate, object_ in g:&#10;        # Compute the filtered statement of the Triples&#10;        subjectTerm = subject.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;        if(not len(subjectTerm) and len(subject.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)) &gt; 1):&#10;            subjectTerm = subject.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-2]&#10;        predicateTerm = predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;        if(not len(predicateTerm) and len(predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)) &gt; 1):&#10;            predicateTerm = predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-2]&#10;        objectTerm = object_.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;        if(not len(objectTerm) and len(object_.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)) &gt; 1):&#10;            objectTerm = object_.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-2]&#10;        if(row[&quot;prefix&quot;] == &quot;FreeBase&quot;):&#10;            subjectTerm = subjectTerm.split(&quot;.&quot;)[-1]&#10;            if(not len(subjectTerm) and len(subjectTerm.split(&quot;.&quot;)) &gt; 1):&#10;                subjectTerm = subjectTerm.split(&quot;.&quot;)[-2]&#10;            predicateTerm = predicateTerm.split(&quot;.&quot;)[-1]&#10;            if(not len(objectTerm) and len(predicateTerm.split(&quot;.&quot;)) &gt; 1):&#10;                predicateTerm = predicateTerm.split(&quot;.&quot;)[-2]&#10;            objectTerm = objectTerm.split(&quot;.&quot;)[-1]&#10;            if(not len(objectTerm) and len(objectTerm.split(&quot;.&quot;)) &gt; 1):&#10;                objectTerm = objectTerm.split(&quot;.&quot;)[-2]&#10;        &#10;        # Check if the triple has to be saved, if there is a predicate selection then checks if that predicate has to be saved&#10;        bool_ = False&#10;        # If there is no predicate selection then save every triple&#10;        if(len(predicates) == 0):&#10;            bool_ = True&#10;        # If there is a predicate selection then check if that predicate has to be saved&#10;        else:&#10;            for pred in predicates[&quot;Predicate&quot;]:&#10;                if(pred == str(predicateTerm) or pred == str(predicate)):&#10;                    bool_ = True&#10;                    break&#10;        # Check if the triple has to be saved&#10;        if(bool_ == True):&#10;            # Save the statement to the List to be added to the DataFrame&#10;            list_.insert(index,{&quot;Date&quot;: date, &quot;Subject&quot;: subject, &quot;Predicate&quot;: predicate, &quot;Object&quot;: object_, &quot;SubjectTerm&quot;: subjectTerm, &quot;PredicateTerm&quot;: predicateTerm, &quot;ObjectTerm&quot;: objectTerm, &quot;Domain&quot;: row[&quot;prefix&quot;], &quot;Domain Version&quot;: row[&quot;VersionName&quot;], &quot;Domain Date&quot;: row[&quot;VersionDate&quot;], &quot;URI&quot;: row[&quot;URI&quot;], &quot;Title&quot;: row[&quot;Title&quot;], &quot;Languages&quot;: row[&quot;Languages&quot;], &quot;Inherited&quot;: 0})&#10;            index += 1&#10;            &#10;            # Save the statement to the ExcelSheet Triples&#10;            inSingleSheet.write_row(inSingleExcel.index, 0, (date, subject, predicate, object_, subjectTerm, predicateTerm, objectTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;], 0))&#10;            inTotalSheet.write_row(inTotalExcel.index, 0, (date, subject, predicate, object_, subjectTerm, predicateTerm, objectTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;], 0))&#10;            # Update the index of both the ExcelSheets&#10;            inSingleExcel.index += 1&#10;            inTotalExcel.index += 1&#10;&#10;            # If the rows of inSingleExcel reach the excel limit then create a new ExcelFile&#10;            if(inSingleExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                inSingleWorkbook.close()&#10;                inSingleExcel.writer.save()&#10;                # Create a new ExcelFile&#10;                inSingleExcel, inSingleWorkbook, inSingleSheet = newExcel(inSingleExcel.num, str(os.path.join(vocabFolder, inFileName + str(inSingleExcel.num) + &quot;.xlsx&quot;)), &quot;Inherited Single Triples&quot;)&#10;                &#10;            # If the rows of totalExcel reach the excel limit then create a new ExcelFile&#10;            if(inTotalExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                inTotalWorkbook.close()&#10;                inTotalExcel.writer.save()&#10;                # Create a new ExcelFile&#10;                inTotalExcel, inTotalWorkbook, inTotalSheet = newExcel(inTotalExcel.num, str(os.path.join(os.path.dirname(vocabFolder), date + &quot;_Inherited_Knowledge-Triples_&quot; + str(inTotalExcel.num) + &quot;.xlsx&quot;)), &quot;Inherited Total Triples&quot;)&#10;&#10;            for n in nxGT:&#10;                for node in nxGT.neighbors(n):&#10;                    if(str(n) == str(object_)):&#10;                        # Compute the filtered statement of the Triples&#10;                        nodeTerm = node.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;                        if(not len(nodeTerm) and len(node.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)) &gt; 1):&#10;                            nodeTerm = node.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-2]&#10;                        &#10;                        # Save the statement to the List to be added to the DataFrame&#10;                        list_.insert(index,{&quot;Date&quot;: date, &quot;Subject&quot;: subject, &quot;Predicate&quot;: predicate, &quot;Object&quot;: node, &quot;SubjectTerm&quot;: subjectTerm, &quot;PredicateTerm&quot;: predicateTerm, &quot;ObjectTerm&quot;: nodeTerm, &quot;Domain&quot;: row[&quot;prefix&quot;], &quot;Domain Version&quot;: row[&quot;VersionName&quot;], &quot;Domain Date&quot;: row[&quot;VersionDate&quot;], &quot;URI&quot;: row[&quot;URI&quot;], &quot;Title&quot;: row[&quot;Title&quot;], &quot;Languages&quot;: row[&quot;Languages&quot;], &quot;Inherited&quot;: 1})&#10;                        index += 1&#10;                        &#10;                        # Save the statement to the ExcelSheet Triples&#10;                        inSingleSheet.write_row(inSingleExcel.index, 0, (date, subject, predicate, node, subjectTerm, predicateTerm, nodeTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;], 1))&#10;                        inTotalSheet.write_row(inTotalExcel.index, 0, (date, subject, predicate, node, subjectTerm, predicateTerm, nodeTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;], 1))&#10;                        # Update the index of both the ExcelSheets&#10;                        inSingleExcel.index += 1&#10;                        inTotalExcel.index += 1&#10;&#10;                        # If the rows of inSingleExcel reach the excel limit then create a new ExcelFile&#10;                        if(inSingleExcel.index == 1048575):&#10;                            #Close the ExcelFile&#10;                            inSingleWorkbook.close()&#10;                            inSingleExcel.writer.save()&#10;                            # Create a new ExcelFile&#10;                            inSingleExcel, inSingleWorkbook, inSingleSheet = newExcel(inSingleExcel.num, str(os.path.join(vocabFolder, inFileName + str(inSingleExcel.num) + &quot;.xlsx&quot;)), &quot;Inherited Single Triples&quot;)&#10;                            &#10;                        # If the rows of totalExcel reach the excel limit then create a new ExcelFile&#10;                        if(inTotalExcel.index == 1048575):&#10;                            #Close the ExcelFile&#10;                            inTotalWorkbook.close()&#10;                            inTotalExcel.writer.save()&#10;                            # Create a new ExcelFile&#10;                            inTotalExcel, inTotalWorkbook, inTotalSheet = newExcel(inTotalExcel.num, str(os.path.join(os.path.dirname(vocabFolder), date + &quot;_Inherited_Knowledge-Triples_&quot; + str(inTotalExcel.num) + &quot;.xlsx&quot;)), &quot;Inherited Total Triples&quot;)&#10;&#10;&#10;    # Close the Excel file of the single vocabulary&#10;    inSingleExcel.writer.book.close()&#10;    inSingleExcel.writer.save()&#10;&#10;    # Return the List to be added to the DataFrame and the relative index&#10;    return inTotalExcel, list_, index&#10;&#10;# Create a new ExcelFile&#10;def newExcel(excelNum, fileName, sheetName):&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    writer = pd.ExcelWriter(fileName, engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;    excelFile_ = ExcelFile(writer, excelNum)&#10;    # Get the xlsxwriter workbook and worksheet objects.&#10;    workbook  = writer.book&#10;    # Add WorkSheet with relative titles and relative bold header &#10;    worksheet = workbook.add_worksheet(sheetName)&#10;    worksheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;SubjectTerm&quot;, &quot;PredicateTerm&quot;, &quot;ObjectTerm&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;, &quot;Inherited&quot;), workbook.add_format({&quot;bold&quot;: True}))&#10;    worksheet.set_column(0, 12, 30)&#10;    # Return the new excelFile_, workbook, worksheet&#10;    return excelFile_, workbook, worksheet&#10;&#10;# Set the inheritance&#10;def setInheritance(subject, object_, inherit, set_):&#10;    # Compute the length of the subject's set&#10;    a = len(set_)&#10;    # Add the subject to the set&#10;    set_.add(subject)&#10;    # Check if the length now is bigger, i.e. a new element has been added&#10;    if(a &lt; len(set_)):&#10;        # Add the new subject and relative first inheritable object&#10;        inherit.at[subject, &quot;Subject&quot;] = subject&#10;        inherit.at[subject, &quot;subOf&quot;] = object_&#10;        inherit.at[subject, &quot;subbed&quot;] = &quot;&quot;&#10;    else:&#10;        # Add a new inheritable object&#10;        subOfs = str(inherit.at[subject, &quot;subOf&quot;])&#10;        inherit.at[subject, &quot;subOf&quot;] = subOfs + &quot; , &quot; + object_&#10;    # Return the dataframe and set relative to inheritance&#10;    return inherit, set_&#10;&#10;# Return the networkx graph used to calculate inheritance&#10;def createNXGraph(inherit):&#10;    # Create the networkx graph used to calculate inheritance&#10;    nxG = nx.DiGraph()&#10;    # Use this set to add a single node for every subject that inherit &#10;    nodes = set()&#10;&#10;    # Iterate over every element of the dataframe containing the informations about inheritance&#10;    for index, row in inherit.iterrows():&#10;        # Get the relative inheritable objects of a subject&#10;        subOfs = str(inherit.at[str(row[&quot;Subject&quot;]), &quot;subOf&quot;])&#10;        l = len(nodes)&#10;        nodes.add(str(row[&quot;Subject&quot;]))&#10;        if(len(nodes) &gt; l):&#10;            nxG.add_node(str(row[&quot;Subject&quot;]))&#10;        for sub in subOfs.split(&quot; , &quot;):&#10;            # Get the relative already inherited objects of a subject&#10;            l = len(nodes)&#10;            nodes.add(sub)&#10;            if(len(nodes) &gt; l):&#10;                nxG.add_node(sub)&#10;            nxG.add_edge(str(row[&quot;Subject&quot;]), sub)&#10;&#10;    # Return the networkx graph used to calculate inheritance&#10;    return nxG&#10;&#10;# Mandatory function for RapidMiner&#10;def rm_main(vocabs, predicates = pd.DataFrame() ):&#10;    # Create the folder used to store the results&#10;    location = os.path.normpath(os.path.expanduser(&quot;~/Desktop/K-Files/&quot;))&#10;    if not os.path.isdir(location):&#10;        os.makedirs(location)&#10;&#10;    # Get the date of the current day of the Parsing&#10;    date = time.strftime(&quot;%Y-%m-%d&quot;, time.gmtime())&#10;&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    inTotalExcel, inTotalWorkbook, inTotalSheet = newExcel(0, str(os.path.join(location, date + &quot;_Inherited_Knowledge-Triples_0.xlsx&quot;)), &quot;Inherited Total Triples&quot;)&#10;&#10;    # Create the DataFrame to save the vocabs' Date of parsing, Subject, Predicate, Object, Domain, Domain Version, Domain Date, URI, Title, Languages&#10;    df = pd.DataFrame(columns=[&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;SubjectTerm&quot;, &quot;PredicateTerm&quot;, &quot;ObjectTerm&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;, &quot;Inherited&quot;])&#10;&#10;    # Iterate for every vocabulary read from the second argument&#10;    for index, row in vocabs.iterrows():&#10;        # Create the Folder &#10;        vocabFolder = str(os.path.join(location, row[&quot;Folder&quot;]))&#10;        if not os.path.isdir(vocabFolder):&#10;            os.makedirs(vocabFolder)&#10;        print(row[&quot;Link&quot;])&#10;        # Add information for each vocabulary&#10;        inTotalExcel, list_, i = parse(vocabFolder, date, row, inTotalExcel, list(), predicates)&#10;        # Save the information on the DataFrame for each vocabulary&#10;        if(i and len(list_)):&#10;            df = df.append(list_)&#10;&#10;    # Close the Excel file of the single vocabulary&#10;    inTotalExcel.writer.book.close()&#10;    inTotalExcel.writer.save()&#10;&#10;    # Return the DataFrame for RapidMiner visualization&#10;    return df"/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
      </operator>
      <operator activated="true" class="write_csv" compatibility="9.2.001" expanded="true" height="82" name="Write CSV Inherited" width="90" x="782" y="340">
        <parameter key="csv_file" value="C:\Users\marco\Desktop\K-Files\FilteredTriples.csv"/>
        <parameter key="column_separator" value="|"/>
        <parameter key="write_attribute_names" value="true"/>
        <parameter key="quote_nominal_values" value="true"/>
        <parameter key="format_date_attributes" value="true"/>
        <parameter key="append_to_file" value="false"/>
        <parameter key="encoding" value="SYSTEM"/>
      </operator>
      <connect from_op="Read Knowledge" from_port="output" to_op="KnowledgeParser_Full" to_port="input 1"/>
      <connect from_op="Read Knowledge (2)" from_port="output" to_op="KnowledgeParser_Filtered" to_port="input 1"/>
      <connect from_op="Read Knowledge (3)" from_port="output" to_op="KnowledgeInheritor" to_port="input 1"/>
      <connect from_op="Read Predicates" from_port="output" to_op="KnowledgeParser_Full" to_port="input 2"/>
      <connect from_op="KnowledgeParser_Full" from_port="output 1" to_op="Write CSV Full" to_port="input"/>
      <connect from_op="Read Predicates (2)" from_port="output" to_op="KnowledgeParser_Filtered" to_port="input 2"/>
      <connect from_op="KnowledgeParser_Filtered" from_port="output 1" to_op="Write CSV Filtered" to_port="input"/>
      <connect from_op="Read Predicates (3)" from_port="output" to_op="KnowledgeInheritor" to_port="input 2"/>
      <connect from_op="KnowledgeInheritor" from_port="output 1" to_op="Write CSV Inherited" to_port="input"/>
      <connect from_op="Write CSV Inherited" from_port="through" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <description align="left" color="yellow" colored="false" height="272" resized="true" width="488" x="510" y="476">Parse all the vocabularies passed from the Excel file, saving Date of scraping, subject, predicate, object, domain, domain version, domain date, URI, Title, Languages for every vocabulary's triple&lt;br&gt;It saves this informations in 2 ways, Full(contains the full path of the triple) and Filtered(contains only the last word of the triple)&lt;br&gt;It uses the Folder column from the input file to create a Folder for every value, and then every vocabulary the relative Folder&lt;br&gt;For each vocabulary it creates an Excel File with its triples in the desidered way&lt;br&gt;For each vocabulary, serialize it in a .nt format, saved in Folder/Resources&lt;br&gt;Furthermore it returns to RapidMiner every triple for saving using the operator Write CSV(as Excel has a 1048575 rows limit)&lt;br/&gt;KnowledgeInheritor also saves the relative triples for a subject with a subClassOf predicate, hence implementing inheritance of the attributes</description>
      <description align="center" color="yellow" colored="false" height="300" resized="false" width="126" x="293" y="447">Read the worksheet of Excel that contains the info about the vocabulatories to transform&lt;br&gt;It must have the first row as: prefix, URI, Title, Languages, VersionName, VersionDate, Link, Folder and then all the vocabularies that you want to parse&lt;br&gt;</description>
      <description align="center" color="yellow" colored="false" height="50" resized="false" width="126" x="160" y="483">Optional, used to filter the triples</description>
    </process>
  </operator>
</process>
