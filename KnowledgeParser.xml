<?xml version="1.0" encoding="UTF-8"?><process version="9.2.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.2.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="read_excel" compatibility="9.2.000" expanded="true" height="68" name="Read Knowledge" width="90" x="45" y="34">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\test.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information"/>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
        <description align="center" color="transparent" colored="false" width="126">Read the worksheet of Excel that contains the info about the vocabulatories to transform&lt;br&gt;It must have the first row as: prefix, URI, Title, Languages, VersionName, VersionDate, Link, Folder and then all the vocabularies that you want to parse&lt;br&gt;</description>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="103" name="KnowledgeParser_Full" width="90" x="246" y="136">
        <parameter key="script" value="# Import libraries&#10;import rdflib&#10;from rdflib import Graph, Namespace&#10;from rdflib.util import guess_format&#10;from rdflib.plugins.parsers.notation3 import N3Parser&#10;import pandas as pd&#10;import os&#10;import time&#10;&#10;# Class to handle the Excel file and relative indexes&#10;class ExcelFile:&#10;    def __init__(self, writer, num = 0):&#10;        self.writer = writer&#10;        self.index = 1&#10;        self.num = num + 1&#10;&#10;# Mandatory function for RapidMiner&#10;def rm_main(vocabs):&#10;    # Create the folder used to store the results&#10;    location = os.path.normpath(os.path.expanduser(&quot;~/Desktop/K-Files/&quot;))&#10;    if not os.path.isdir(location):&#10;        os.makedirs(location)&#10;&#10;    # Get the date of the current day of the Parsing&#10;    date = time.strftime(&quot;%Y-%m-%d&quot;, time.gmtime())&#10;&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    totalWriter = pd.ExcelWriter(str(os.path.join(location, date + &quot;_Full_Knowledge-Triples_0.xlsx&quot;)), engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;    totalExcel = ExcelFile(totalWriter)&#10;    # Get the xlsxwriter workbook and worksheet objects.&#10;    totalWorkbook  = totalWriter.book&#10;    totalFullSheet = totalWorkbook.add_worksheet(&quot;Total Full Triples&quot;)&#10;    totalFullSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), totalWorkbook.add_format({&quot;bold&quot;: True}))&#10;    totalFullSheet.set_column(0, 8, 30)&#10;&#10;    # Create the DataFrame to save the vocabs' Date of parsing, Subject, Predicate, Object, Domain, Domain Version, Domain Date, URI, Title, Languages&#10;    df = pd.DataFrame(columns=[&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;])&#10;&#10;    # Iterate for every vocabulary read from the second argument&#10;    for index, row in vocabs.iterrows():&#10;        # Create the Folder &#10;        vocabFolder = str(os.path.join(location, row[&quot;Folder&quot;]))&#10;        if not os.path.isdir(vocabFolder):&#10;            os.makedirs(vocabFolder)&#10;        &#10;        # Create the list used to add the triples of the vocabulary to the DataFrame&#10;        list_ = list()&#10;&#10;        # Try to create the graph to analyze the vocabulary&#10;        try:&#10;            g = Graph()&#10;            format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-1]&#10;            if(format_ == &quot;txt&quot;):&#10;                format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-2]&#10;            format_ = format_.split(&quot;?&quot;)[0]&#10;            result = g.parse(row[&quot;Link&quot;], format=guess_format(format_), publicID=row[&quot;prefix&quot;])&#10;        except Exception as e:&#10;            # In case of an error during the graph's initiation, print the error and return an empty list&#10;            print(str(e) + &quot;\n&quot;)    &#10;            return totalExcel, list_, 0&#10;&#10;        # Serialize the vocabulary in a .nt format saved in vocabFolder/Resources with the same name of the Excel File&#10;        try:&#10;            resourceDestination = os.path.join(vocabFolder, &quot;Resources&quot;)&#10;            if not os.path.isdir(resourceDestination):&#10;                os.makedirs(resourceDestination)&#10;            fileName = date + &quot;_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;]&#10;            g.serialize(destination=str(os.path.join(resourceDestination, fileName)) + &quot;.nt&quot;, format='nt')&#10;        except Exception as e:&#10;            # In case of an error during the graph's serialization, print the error&#10;            print(str(e) + &quot;\n&quot;)&#10;&#10;        # Get the totalExcel file and relative worksheets&#10;        totalWorkbook = totalExcel.writer.book&#10;        totalFullSheet = totalWorkbook.get_worksheet_by_name(&quot;Total Full Triples&quot;)&#10;&#10;        # Elaborate the fileName of the vocabulary&#10;        fileName = date + &quot;_Full_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;] + &quot;_&quot;&#10;        # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;        singleWriter = pd.ExcelWriter(str(os.path.join(vocabFolder, fileName + &quot;0.xlsx&quot;)), engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;        singleExcel = ExcelFile(singleWriter)&#10;        # Get the xlsxwriter workbook and worksheet objects.&#10;        singleWorkbook  = singleWriter.book&#10;        singleFullSheet = singleWorkbook.add_worksheet(&quot;Single Full Triples&quot;)&#10;        singleFullSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), singleWorkbook.add_format({&quot;bold&quot;: True}))&#10;        singleFullSheet.set_column(0, 8, 30)&#10;        &#10;        # For each statement present in the graph obtained store the triples&#10;        index = 0&#10;        for subject, predicate, object_ in g:&#10;            # Save the full statement to the ExcelSheet FullTriples&#10;            singleFullSheet.write_row(singleExcel.index, 0, (date, subject, predicate, object_, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;            totalFullSheet.write_row(totalExcel.index, 0, (date, subject, predicate, object_, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;            # Save the Full statement to the List to be added to the DataFrame, and update the index&#10;            list_.insert(index,{&quot;Date&quot;: date, &quot;Subject&quot;: subject, &quot;Predicate&quot;: predicate, &quot;Object&quot;: object_, &quot;Domain&quot;: row[&quot;prefix&quot;], &quot;Domain Version&quot;: row[&quot;VersionName&quot;], &quot;Domain Date&quot;: row[&quot;VersionDate&quot;], &quot;URI&quot;: row[&quot;URI&quot;], &quot;Title&quot;: row[&quot;Title&quot;], &quot;Languages&quot;: row[&quot;Languages&quot;]})&#10;            index += 1&#10;            # Update the index of both the ExcelSheets&#10;            singleExcel.index += 1&#10;            totalExcel.index += 1&#10;&#10;            # If the rows reach the excel limit then create a new ExcelFile&#10;            if(singleExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                singleWorkbook.close()&#10;                singleExcel.writer.save()&#10;                # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;                singleWriter = pd.ExcelWriter(str(os.path.join(vocabFolder, fileName + str(singleExcel.num) + &quot;.xlsx&quot;)), engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;                singleExcel = ExcelFile(singleWriter, singleExcel.num)&#10;                # Get the xlsxwriter workbook and worksheet objects.&#10;                singleWorkbook  = singleWriter.book&#10;                # Add WorkSheet with relative titles and relative bold header &#10;                singleFullSheet = singleWorkbook.add_worksheet(&quot;Single Full Triples&quot;)&#10;                singleFullSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), singleWorkbook.add_format({&quot;bold&quot;: True}))&#10;                singleFullSheet.set_column(0, 8, 30)&#10;&#10;            # If the rows reach the excel limit then create a new ExcelFile&#10;            if(totalExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                totalWorkbook.close()&#10;                totalExcel.writer.save()&#10;&#10;                # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;                totalWriter = pd.ExcelWriter(str(os.path.join(os.path.dirname(vocabFolder), date + &quot;_Full_Knowledge-Triples_&quot; + str(totalExcel.num) + &quot;.xlsx&quot;)), engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;                totalExcel = ExcelFile(totalWriter, totalExcel.num)&#10;                # Get the xlsxwriter workbook and worksheet objects.&#10;                totalWorkbook  = totalWriter.book&#10;                # Add WorkSheet with relative titles and relative bold header &#10;                totalFullSheet = totalWorkbook.add_worksheet(&quot;Total Full Triples&quot;)&#10;                totalFullSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), totalWorkbook.add_format({&quot;bold&quot;: True}))&#10;                totalFullSheet.set_column(0, 8, 30)&#10;&#10;        # Close the Excel file of the single vocabulary&#10;        singleExcel.writer.book.close()&#10;        singleExcel.writer.save()&#10;        &#10;        # Save the information on the DataFrame for each vocabulary&#10;        if(index and len(list_)):&#10;            df = df.append(list_)&#10;&#10;    # Close the Excel file of the total vocabularies&#10;    totalExcel.writer.book.close()&#10;    totalExcel.writer.save()&#10;&#10;    # Return the DataFrame for RapidMiner storing module&#10;    return df"/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
      </operator>
      <operator activated="true" class="write_csv" compatibility="9.2.000" expanded="true" height="82" name="Write CSV Full" width="90" x="514" y="136">
        <parameter key="csv_file" value="C:\Users\marco\Desktop\K-Files\FullWordNet.csv"/>
        <parameter key="column_separator" value=";"/>
        <parameter key="write_attribute_names" value="true"/>
        <parameter key="quote_nominal_values" value="true"/>
        <parameter key="format_date_attributes" value="true"/>
        <parameter key="append_to_file" value="false"/>
        <parameter key="encoding" value="SYSTEM"/>
      </operator>
      <operator activated="true" class="read_excel" compatibility="9.2.000" expanded="true" height="68" name="Read Knowledge (2)" width="90" x="45" y="493">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\test.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information"/>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
        <description align="center" color="transparent" colored="false" width="126">Read the worksheet of Excel that contains the info about the vocabulatories to transform&lt;br&gt;It must have the first row as: prefix, URI, Title, Languages, VersionName, VersionDate, Link, Folder and then all the vocabularies that you want to parse&lt;br&gt;</description>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="103" name="KnowledgeParser_Filtered" width="90" x="246" y="340">
        <parameter key="script" value="# Import libraries&#10;import rdflib&#10;from rdflib import Graph, Namespace&#10;from rdflib.util import guess_format&#10;from rdflib.plugins.parsers.notation3 import N3Parser&#10;import pandas as pd&#10;import os&#10;import time&#10;&#10;# Class to handle the Excel file and relative indexes&#10;class ExcelFile:&#10;    def __init__(self, writer, num = 0):&#10;        self.writer = writer&#10;        self.index = 1&#10;        self.num = num + 1&#10;&#10;# Mandatory function for RapidMiner&#10;def rm_main(vocabs):&#10;    # Create the folder used to store the results&#10;    location = os.path.normpath(os.path.expanduser(&quot;~/Desktop/K-Files/&quot;))&#10;    if not os.path.isdir(location):&#10;        os.makedirs(location)&#10;&#10;    # Get the date of the current day of the Parsing&#10;    date = time.strftime(&quot;%Y-%m-%d&quot;, time.gmtime())&#10;&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    totalWriter = pd.ExcelWriter(str(os.path.join(location, date + &quot;_Filtered_Knowledge-Triples_0.xlsx&quot;)), engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;    totalExcel = ExcelFile(totalWriter)&#10;    # Get the xlsxwriter workbook and worksheet objects.&#10;    totalWorkbook  = totalWriter.book&#10;    # Add WorkSheets with relative titles and relative bold header &#10;    totalFilteredSheet = totalWorkbook.add_worksheet(&quot;Total Filtered Triples&quot;)&#10;    totalFilteredSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), totalWorkbook.add_format({&quot;bold&quot;: True}))&#10;    totalFilteredSheet.set_column(0, 8, 30)&#10;&#10;    # Create the DataFrame to save the vocabs' Date of parsing, Subject, Predicate, Object, Domain, Domain Version, Domain Date, URI, Title, Languages&#10;    df = pd.DataFrame(columns=[&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;])&#10;&#10;    # Iterate for every vocabulary read from the second argument&#10;    for index, row in vocabs.iterrows():&#10;        # Create the Folder &#10;        vocabFolder = str(os.path.join(location, row[&quot;Folder&quot;]))&#10;        if not os.path.isdir(vocabFolder):&#10;            os.makedirs(vocabFolder)&#10;        &#10;        # Create the list used to add the triples of the vocabulary to the DataFrame&#10;        list_ = list()&#10;&#10;        # Try to create the graph to analyze the vocabulary&#10;        try:&#10;            g = Graph()&#10;            format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-1]&#10;            if(format_ == &quot;txt&quot;):&#10;                format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-2]&#10;            format_ = format_.split(&quot;?&quot;)[0]&#10;            result = g.parse(row[&quot;Link&quot;], format=guess_format(format_), publicID=row[&quot;prefix&quot;])&#10;        except Exception as e:&#10;            # In case of an error during the graph's initiation, print the error and return an empty list&#10;            print(str(e) + &quot;\n&quot;)    &#10;            return totalExcel, list_, 0&#10;&#10;        # Serialize the vocabulary in a .nt format saved in vocabFolder/Resources with the same name of the Excel File&#10;        try:&#10;            resourceDestination = os.path.join(vocabFolder, &quot;Resources&quot;)&#10;            if not os.path.isdir(resourceDestination):&#10;                os.makedirs(resourceDestination)&#10;            fileName = date + &quot;_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;]&#10;            g.serialize(destination=str(os.path.join(resourceDestination, fileName)) + &quot;.nt&quot;, format='nt')&#10;        except Exception as e:&#10;            # In case of an error during the graph's serialization, print the error&#10;            print(str(e) + &quot;\n&quot;)    &#10;&#10;        # Get the totalExcel file and relative worksheets&#10;        totalWorkbook = totalExcel.writer.book&#10;        totalFilteredSheet = totalWorkbook.get_worksheet_by_name(&quot;Total Filtered Triples&quot;)&#10;&#10;        # Elaborate the fileName of the vocabulary&#10;        fileName = date + &quot;_Filtered_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;] + &quot;_&quot;&#10;        # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;        singleWriter = pd.ExcelWriter(str(os.path.join(vocabFolder, fileName + &quot;0.xlsx&quot;)), engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;        singleExcel = ExcelFile(singleWriter)&#10;        # Get the xlsxwriter workbook and worksheet objects.&#10;        singleWorkbook  = singleWriter.book&#10;        # Add WorkSheets with relative titles and relative bold header &#10;        singleFilteredSheet = singleWorkbook.add_worksheet(&quot;Single Filtered Triples&quot;)&#10;        singleFilteredSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), singleWorkbook.add_format({&quot;bold&quot;: True}))&#10;        singleFilteredSheet.set_column(0, 8, 30)&#10;        &#10;        # For each statement present in the graph obtained store the triples&#10;        index = 0&#10;        for subject, predicate, object_ in g:&#10;            # Save the full statement to the ExcelSheet FullTriples&#10;            subjectTerm = subject.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;            predicateTerm = predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;            objectTerm = object_.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)[-1]&#10;            if(row[&quot;prefix&quot;] == &quot;FreeBase&quot;):&#10;                subjectTerm = subjectTerm.split(&quot;.&quot;)[-1]&#10;                predicateTerm = predicateTerm.split(&quot;.&quot;)[-1]&#10;                objectTerm = objectTerm.split(&quot;.&quot;)[-1]&#10;            # Save the Filtered statement to the List to be added to the DataFrame&#10;            list_.insert(index,{&quot;Date&quot;: date, &quot;Subject&quot;: subjectTerm, &quot;Predicate&quot;: predicateTerm, &quot;Object&quot;: objectTerm, &quot;Domain&quot;: row[&quot;prefix&quot;], &quot;Domain Version&quot;: row[&quot;VersionName&quot;], &quot;Domain Date&quot;: row[&quot;VersionDate&quot;], &quot;URI&quot;: row[&quot;URI&quot;], &quot;Title&quot;: row[&quot;Title&quot;], &quot;Languages&quot;: row[&quot;Languages&quot;]})&#10;            index += 1&#10;            # Save the Filtered statement to the ExcelSheet FilteredTriples&#10;            singleFilteredSheet.write_row(singleExcel.index, 0, (date, subjectTerm, predicateTerm, objectTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;            totalFilteredSheet.write_row(totalExcel.index, 0, (date, subjectTerm, predicateTerm, objectTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;            # Update the index of both the ExcelSheets&#10;            singleExcel.index += 1&#10;            totalExcel.index += 1&#10;            # If the rows reach the excel limit then create a new ExcelFile&#10;            if(singleExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                singleWorkbook.close()&#10;                singleExcel.writer.save()&#10;                # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;                singleWriter = pd.ExcelWriter(str(os.path.join(vocabFolder, fileName + str(singleExcel.num) + &quot;.xlsx&quot;)), engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;                singleExcel = ExcelFile(singleWriter, singleExcel.num)&#10;                # Get the xlsxwriter workbook and worksheet objects.&#10;                singleWorkbook  = singleWriter.book&#10;                # Add WorkSheet with relative titles and relative bold header &#10;                singleFilteredSheet = singleWorkbook.add_worksheet(&quot;Single Filtered Triples&quot;)&#10;                singleFilteredSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), singleWorkbook.add_format({&quot;bold&quot;: True}))&#10;                singleFilteredSheet.set_column(0, 8, 30)&#10;            # If the rows reach the excel limit then create a new ExcelFile&#10;            if(totalExcel.index == 1048575):&#10;                #Close the ExcelFile&#10;                totalWorkbook.close()&#10;                totalExcel.writer.save()&#10;                # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;                totalWriter = pd.ExcelWriter(str(os.path.join(os.path.dirname(vocabFolder), date + &quot;_Filtered_Knowledge-Triples_&quot; + str(totalExcel.num) + &quot;.xlsx&quot;)), engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;                totalExcel = ExcelFile(totalWriter, totalExcel.num)&#10;                # Get the xlsxwriter workbook and worksheet objects.&#10;                totalWorkbook  = totalWriter.book&#10;                # Add WorkSheet with relative titles and relative bold header &#10;                totalFilteredSheet = totalWorkbook.add_worksheet(&quot;Total Filtered Triples&quot;)&#10;                totalFilteredSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), totalWorkbook.add_format({&quot;bold&quot;: True}))&#10;                totalFilteredSheet.set_column(0, 8, 30)&#10;&#10;        # Close the Excel file of the single vocabulary&#10;        singleExcel.writer.book.close()&#10;        singleExcel.writer.save()&#10;&#10;        # Save the information on the DataFrame for each vocabulary&#10;        if(index and len(list_)):&#10;            df = df.append(list_)&#10;&#10;    # Close the Excel file of the total vocabularies&#10;    totalExcel.writer.book.close()&#10;    totalExcel.writer.save()&#10;&#10;    # Return the DataFrame for RapidMiner storing module&#10;    return df"/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
      </operator>
      <operator activated="true" class="write_csv" compatibility="9.2.000" expanded="true" height="82" name="Write CSV Filtered" width="90" x="514" y="340">
        <parameter key="csv_file" value="C:\Users\marco\Desktop\K-Files\FilteredWordNet.csv"/>
        <parameter key="column_separator" value=";"/>
        <parameter key="write_attribute_names" value="true"/>
        <parameter key="quote_nominal_values" value="true"/>
        <parameter key="format_date_attributes" value="true"/>
        <parameter key="append_to_file" value="false"/>
        <parameter key="encoding" value="SYSTEM"/>
      </operator>
      <connect from_op="Read Knowledge" from_port="output" to_op="KnowledgeParser_Full" to_port="input 1"/>
      <connect from_op="KnowledgeParser_Full" from_port="output 1" to_op="Write CSV Full" to_port="input"/>
      <connect from_op="Write CSV Full" from_port="through" to_port="result 1"/>
      <connect from_op="Read Knowledge (2)" from_port="output" to_op="KnowledgeParser_Filtered" to_port="input 1"/>
      <connect from_op="KnowledgeParser_Filtered" from_port="output 1" to_op="Write CSV Filtered" to_port="input"/>
      <connect from_op="Write CSV Filtered" from_port="through" to_port="result 2"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <portSpacing port="sink_result 3" spacing="0"/>
      <description align="left" color="yellow" colored="false" height="272" resized="true" width="488" x="206" y="454">Parse all the vocabularies passed from the Excel file, saving Date of scraping, subject, predicate, object, domain, domain version, domain date, URI, Title, Languages for every vocabulary's triple&lt;br&gt;It saves this informations in 2 ways, Full(contains the full path of the triple) and Filtered(contains only the last word of the triple)&lt;br&gt;It uses the Folder column from the input file to create a Folder for every value, and then every vocabulary the relative Folder&lt;br&gt;For each vocabulary it creates an Excel File with its triples in the desidered way&lt;br&gt;For each vocabulary, serialize it in a .nt format, saved in Folder/Resources&lt;br&gt;Furthermore it returns to RapidMiner every triple for saving using the operator Write CSV(as Excel has a 1048575 rows limit)</description>
    </process>
  </operator>
</process>
