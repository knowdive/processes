<?xml version="1.0" encoding="UTF-8"?><process version="9.2.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.2.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="read_excel" compatibility="9.2.000" expanded="true" height="68" name="Read Input Destination File" width="90" x="45" y="85">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\Internship\Results\LOV_Latest.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="2"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="false"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information">
          <parameter key="0" value="A.true.polynominal.attribute"/>
          <parameter key="1" value="B.true.polynominal.attribute"/>
        </list>
        <parameter key="read_not_matching_values_as_missings" value="false"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
        <description align="center" color="transparent" colored="false" width="126">Read the worksheet of Excel that contains the folder and name of where to save the File that will contain the info about LOV's vocabularies, it can be the same file from where the informations are read&lt;br&gt;The worksheet must have the first 2 cells of the first row as:&lt;br&gt;[0,0]: FolderPath&lt;br&gt;[0,1]: FileName</description>
      </operator>
      <operator activated="true" class="read_excel" compatibility="9.2.000" expanded="true" height="68" name="Read Vocabularies File" width="90" x="179" y="187">
        <parameter key="excel_file" value="C:\Users\marco\Desktop\Internship\Results\LOV_Latest.xlsx"/>
        <parameter key="sheet_selection" value="sheet number"/>
        <parameter key="sheet_number" value="1"/>
        <parameter key="imported_cell_range" value="A1"/>
        <parameter key="encoding" value="SYSTEM"/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="date_format" value=""/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information">
          <parameter key="0" value="prefix.true.polynominal.attribute"/>
          <parameter key="1" value="URI.true.polynominal.attribute"/>
          <parameter key="2" value="Title.true.polynominal.attribute"/>
          <parameter key="3" value="Languages.true.polynominal.attribute"/>
          <parameter key="4" value="VersionName.true.polynominal.attribute"/>
          <parameter key="5" value="VersionDate.true.polynominal.attribute"/>
          <parameter key="6" value="Link.true.polynominal.attribute"/>
          <parameter key="7" value="Folder.true.polynominal.attribute"/>
        </list>
        <parameter key="read_not_matching_values_as_missings" value="false"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
        <description align="center" color="transparent" colored="false" width="126">Read the worksheet of Excel that contains the info about the vocabulatories to transform&lt;br&gt;It must have the first row as: prefix, URI, Title, Languages, VersionName, VersionDate, Link, Folder and then all the vocabularies that you want to parse&lt;br&gt;</description>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="124" name="vocab_Parser" width="90" x="514" y="187">
        <parameter key="script" value="# Import libraries&#10;import rdflib&#10;from rdflib import Graph, Namespace&#10;from rdflib.util import guess_format&#10;from rdflib.plugins.parsers.notation3 import N3Parser&#10;from pathlib import Path&#10;import pandas as pd&#10;import os&#10;import time&#10;import re&#10;&#10;# Class to handle the Excel file and relative indexes&#10;class ExcelFile:&#10;    def __init__(self, writer, num = -1):&#10;        self.writer = writer&#10;        self.index = 1&#10;        self.num = num + 1&#10;&#10;# Parse the given file and add its information to the file Excel given as third parameter&#10;def parse(vocabFolder, date, row, list_):&#10;    # Try to create the graph to analyze the vocabulary&#10;    try:&#10;        g = Graph()&#10;        format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-1]&#10;        if(format_ == &quot;txt&quot;):&#10;            format_ = row[&quot;Link&quot;].split(&quot;.&quot;)[-2]&#10;        format_ = format_.split(&quot;?&quot;)[0]&#10;        result = g.parse(row[&quot;Link&quot;], format=guess_format(format_), publicID=row[&quot;prefix&quot;])&#10;    except Exception as e:&#10;        # In case of an error during the graph's initiation, print the error and return an empty list&#10;        print(str(e) + &quot;\n&quot;)    &#10;        return list_, 0&#10;&#10;    # Serialize the vocabulary in a .nt format saved in vocabFolder/Resources with the same name of the Excel File&#10;    try:&#10;        resourceDestination = os.path.join(vocabFolder, &quot;Resources&quot;)&#10;        if not os.path.isdir(resourceDestination):&#10;            os.makedirs(resourceDestination)&#10;        fileName = date + &quot;_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;]&#10;        g.serialize(destination=str(os.path.join(resourceDestination, fileName)) + &quot;.nt&quot;, format='nt')&#10;    except Exception as e:&#10;        # In case of an error during the graph's serialization, print the error&#10;        print(str(e) + &quot;\n&quot;)    &#10;&#10;    # Elaborate the fileName of the vocabulary&#10;    fileName = date + &quot;_&quot; + row[&quot;prefix&quot;] + &quot;_&quot; + row[&quot;VersionName&quot;] + &quot;_&quot; + row[&quot;VersionDate&quot;]&#10;    # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;    writer = pd.ExcelWriter(str(os.path.join(vocabFolder, fileName)) + &quot;.xlsx&quot;, engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;    excel = ExcelFile(writer)&#10;    # Get the xlsxwriter workbook and worksheet objects.&#10;    workbook  = writer.book&#10;    # Add WorkSheets with relative titles and relative bold header &#10;    partialSheet = workbook.add_worksheet(&quot;Partial Triples&quot;)&#10;    partialSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), workbook.add_format({&quot;bold&quot;: True}))&#10;    partialSheet.set_column(0, 8, 30)&#10;    fullSheet = workbook.add_worksheet(&quot;Full Triples&quot;)&#10;    fullSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), workbook.add_format({&quot;bold&quot;: True}))&#10;    fullSheet.set_column(0, 8, 30)&#10;    &#10;    # For each statement present in the graph obtained store the triples&#10;    index = 0&#10;    for subject, predicate, object_ in g:&#10;        # Save the full statement to the ExcelSheet FullTriples&#10;        fullSheet.write_row(excel.index, 0, (date, subject, predicate, object_, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;        subjectTerm = subject.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)&#10;        subjectTerm = subjectTerm[len(subjectTerm)-1]&#10;        predicateTerm = predicate.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)&#10;        predicateTerm = predicateTerm[len(predicateTerm)-1]&#10;        objectTerm = object_.replace(&quot;/&quot;, &quot;#&quot;).split(&quot;#&quot;)&#10;        objectTerm = objectTerm[len(objectTerm)-1]&#10;        # Save the partial statement to the List to be added to the DataFrame&#10;        list_.insert(index,{&quot;Date&quot;: date, &quot;Subject&quot;: subjectTerm, &quot;Predicate&quot;: predicateTerm, &quot;Object&quot;: objectTerm, &quot;Domain&quot;: row[&quot;prefix&quot;], &quot;Domain Version&quot;: row[&quot;VersionName&quot;], &quot;Domain Date&quot;: row[&quot;VersionDate&quot;], &quot;URI&quot;: row[&quot;URI&quot;], &quot;Title&quot;: row[&quot;Title&quot;], &quot;Languages&quot;: row[&quot;Languages&quot;]})&#10;        index += 1&#10;        # Save the partial statement to the ExcelSheet PartialTriples&#10;        partialSheet.write_row(excel.index, 0, (date, subjectTerm, predicateTerm, objectTerm, row[&quot;prefix&quot;], row[&quot;VersionName&quot;], row[&quot;VersionDate&quot;], row[&quot;URI&quot;], row[&quot;Title&quot;], row[&quot;Languages&quot;]))&#10;        # Update the index of both the ExcelSheets&#10;        excel.index += 1&#10;        # If the rows reach the excel limit then create a new ExcelFile&#10;        if(excel.index == 1048575):&#10;            #Close the ExcelFile&#10;            workbook.close()&#10;            excel.writer.save()&#10;            # Create a Pandas Excel writer using XlsxWriter as the engine.&#10;            writer = pd.ExcelWriter(str(os.path.join(vocabFolder, fileName)) + str(excel.num) + &quot;.xlsx&quot;, engine='xlsxwriter', options={'strings_to_urls': False, 'constant_memory': True, 'nan_inf_to_errors': True})&#10;            excel = ExcelFile(writer, excel.num)&#10;            # Get the xlsxwriter workbook and worksheet objects.&#10;            workbook  = writer.book&#10;            # Add WorkSheet with relative titles and relative bold header &#10;            partialSheet = workbook.add_worksheet(&quot;Partial Triples&quot;)&#10;            partialSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), workbook.add_format({&quot;bold&quot;: True}))&#10;            partialSheet.set_column(0, 8, 30)&#10;            # Add WorkSheet with relative titles and relative bold header &#10;            fullSheet = workbook.add_worksheet(&quot;Full Triples&quot;)&#10;            fullSheet.write_row(0, 0, (&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;), workbook.add_format({&quot;bold&quot;: True}))&#10;            fullSheet.set_column(0, 8, 30)&#10;&#10;    # Close the Excel file of the single vocabulary&#10;    excel.writer.book.close()&#10;    excel.writer.save()&#10;&#10;    # Return the List to be added to the DataFrame and the relative index&#10;    return list_, index&#10;&#10;# Mandatory function for RapidMiner&#10;def rm_main(data, vocabs):&#10;    # Get the FolderPath used to store every vocabulary's triples and the FileName used to store the resulting DataFrame with all the triples&#10;    location = &quot;C:\\Users\\marco\\Desktop\\Internship\\Results\\&quot;&#10;    destination = &quot;vocabs&quot;&#10;    if(len(data)):&#10;        location = data.iloc[0,0]&#10;        destination = data.iloc[0,1]&#10;    if not os.path.isdir(location):&#10;        os.makedirs(location)&#10;&#10;    # Get the date of the current day of the Parsing&#10;    date = time.strftime(&quot;%Y-%m-%d&quot;, time.gmtime())&#10;&#10;    # Create the DataFrame to save the vocabs' Date of parsing, Subject, Predicate, Object, Domain, Domain Version, Domain Date, URI, Title, Languages&#10;    df = pd.DataFrame(columns=[&quot;Date&quot;, &quot;Subject&quot;, &quot;Predicate&quot;, &quot;Object&quot;, &quot;Domain&quot;, &quot;Domain Version&quot;, &quot;Domain Date&quot;, &quot;URI&quot;, &quot;Title&quot;, &quot;Languages&quot;])&#10;&#10;    # Iterate for every vocabulary read from the second argument&#10;    for index, row in vocabs.iterrows():&#10;        # Create the Folder &#10;        vocabFolder = str(os.path.join(location, row[&quot;Folder&quot;]))&#10;        if not os.path.isdir(vocabFolder):&#10;            os.makedirs(vocabFolder)&#10;        &#10;        # Add information for each vocabulary&#10;        list_, i = parse(vocabFolder, date, row, list())&#10;        # Save the information on the DataFrame for each vocabulary&#10;        if(i and len(list_)):&#10;            df = df.append(list_)&#10;&#10;    &#10;    # Save the DataFrame using the parameters from the first argument, in a csv file(because it may exceed Excel limit of rows)&#10;    df.to_csv(str(os.path.join(location, destination)) + &quot;.csv&quot;)&#10;&#10;    # Return the DataFrame for RapidMiner visualization&#10;    return df"/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
      </operator>
      <operator activated="true" class="store" compatibility="9.2.000" expanded="true" height="68" name="Store" width="90" x="715" y="187">
        <parameter key="repository_entry" value="../Data/Triples"/>
      </operator>
      <connect from_op="Read Input Destination File" from_port="output" to_op="vocab_Parser" to_port="input 1"/>
      <connect from_op="Read Vocabularies File" from_port="output" to_op="vocab_Parser" to_port="input 2"/>
      <connect from_op="vocab_Parser" from_port="output 1" to_op="Store" to_port="input"/>
      <connect from_op="Store" from_port="through" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <description align="left" color="yellow" colored="false" height="278" resized="true" width="465" x="385" y="328">Parse all the vocabularies passed from the Excel file, saving Date of scraping, subject, predicate, object, domain, domain version, domain date, URI, Title, Languages for every vocabulary's triple&lt;br&gt;It saves this informations in 2 sheets, FullTriples(contains the full path of the triple) and PartialTriples(contains only the last word of the triple)&lt;br&gt;It uses the Folder column from the input file to create a Folder for every value, and then every vocabulary the relative Folder&lt;br&gt;For each vocabulary it creates an Excel File with its triples&lt;br/&gt;For each vocabulary, serialize it in a .nt format, saved in Folder/Resources&lt;br&gt;Furthermore it returns to RapidMiner every triple for visualization, then it save it in a single csv file, named with the values from the first Excel File input</description>
    </process>
  </operator>
</process>
