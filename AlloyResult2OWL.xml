<?xml version="1.0" encoding="UTF-8"?><process version="9.6.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.4.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="logfile" value="/Users/mattiafumagalli/Desktop/prova.log"/>
    <parameter key="resultfile" value="/Users/mattiafumagalli/prova.res"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="UTF-8"/>
    <process expanded="true">
      <operator activated="true" class="set_macros" compatibility="9.6.000" expanded="true" height="68" name="Set Macros" width="90" x="447" y="442">
        <list key="macros">
          <parameter key="inputFile" value="/home/marco/Desktop/Alloy/Converter/investigation.v00"/>
          <parameter key="outputDirectory" value="/home/marco/Desktop/Alloy/Converter/"/>
          <parameter key="inputDirectory" value="/home/marco/Desktop/Alloy/Converter/"/>
        </list>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="82" name="Alloy2Ontology" width="90" x="916" y="442">
        <parameter key="script" value="#!/usr/bin/env python&#10;# -*- coding: utf-8 -*-&#10;&#10;import os&#10;from os import listdir&#10;from os.path import isfile, join&#10;import pandas as pd&#10;import ontospy&#10;import re&#10;&#10;&#10;import rdflib&#10;from rdflib import Graph, Literal, RDFS, RDF, OWL, Namespace, URIRef&#10;from rdflib.util import guess_format&#10;from rdflib.plugins.parsers.notation3 import N3Parser&#10;&#10;&#10;&#10;def nameOf(text):&#10;    return (str(text).split(&quot;/&quot;))[-1].split(&quot;#&quot;)[-1]&#10;&#10;&#10;# Return identifier of the Alloy and related instances&#10;def scrapeLine(line):&#10;&#9;if(&quot;this&quot; in line):&#10;&#9;&#9;instances = line.split(&quot;{&quot;)[1].split(&quot;}&quot;)[0]&#10;&#9;&#9;if(instances):&#10;&#9;&#9;&#9;identifier = line.split(&quot;=&quot;)[0].split(&quot;/&quot;)[-1].split(&quot;:&quot;)[-1]&#10;&#9;&#9;&#9;if(identifier == &quot;TOP&quot; or identifier == &quot;Individual&quot;):&#10;&#9;&#9;&#9;&#9;return &quot;&quot;, &quot;&quot;&#10;&#9;&#9;&#9;#print(instances + &quot; &quot; + identifier)&#10;&#9;&#9;&#9;return instances, identifier&#10;&#9;return &quot;&quot;, &quot;&quot;&#10;&#10;&#10;def rm_main():&#10;&#10;&#9;# Create the directory in which store the new vocabulary&#10;&#9;outputDirectory = &quot;%{outputDirectory}&quot;&#10;&#9;if not os.path.isdir(outputDirectory):&#10;&#9;&#9;os.makedirs(outputDirectory)&#10;&#10;&#9;# Get inputFile name to generate graph&#10;&#9;inputFile = &quot;%{inputFile}&quot; #, people.owl, Animal.owl, schema_2020-03-10.n3&#10;&#10;&#9;# Try to create the graph to analyze the vocabulary&#10;&#9;try:&#10;&#9;&#9;g = Graph()&#10;&#9;&#9;format_ = inputFile.split(&quot;.&quot;)[-1]&#10;&#9;&#9;if(format_ == &quot;txt&quot;):&#10;&#9;&#9;&#9;format_ = inputFile.split(&quot;.&quot;)[-2]&#10;&#9;&#9;format_ = format_.split(&quot;?&quot;)[0]&#10;&#9;&#9;result = g.parse(inputFile, format=guess_format(format_))&#10;&#9;except Exception as e:&#10;&#9;&#9;# In case of an error during the graph's initiation, print the error and return an empty list&#10;&#9;&#9;print(str(e) + &quot;\n&quot;)    &#10;&#9;&#9;return -1&#10;&#10;&#9;# Define Ontology Analyser&#9;&#10;&#9;o = ontospy.Ontospy()&#10;&#9;# Load Ontology&#10;&#9;o.load_rdf(inputFile)&#10;&#9;o.build_all()&#10;&#10;&#9;# Get original namespace&#10;&#9;originalURI = str(o.namespaces[0][1])&#10;&#9;nmspc = Namespace(originalURI)&#10;&#10;&#9;# Add Classes&#10;&#9;classDict = dict()&#10;&#9;for class_ in o.all_classes:&#10;&#9;&#9;#print(&quot;Class: &quot; + str(class_.uri))&#10;&#9;&#9;className = nameOf(class_.uri)&#10;&#9;&#9;classDict[className] = class_.uri&#10;&#9;# Add Proprieties&#10;&#9;propertyDict = dict()&#10;&#9;for property_ in o.all_properties:&#10;&#9;&#9;#print(&quot;Property: &quot; + str(property_.uri))&#10;&#9;&#9;propertyName = nameOf(property_.uri)&#10;&#9;&#9;propertyDict[propertyName] = property_.uri&#10;&#10;&#9;index = 0&#10;&#9;inputDirectory = &quot;%{inputDirectory}&quot;&#10;&#9;AlloyFiles = [join(inputDirectory, f) for f in listdir(inputDirectory) if ( (isfile(join(inputDirectory, f))) and (&quot;.txt&quot; in f[-4:]) )]&#10;&#9;print(AlloyFiles)&#10;&#9;for AlloyResult in AlloyFiles:&#10;&#9;&#9;with open(AlloyResult) as Alloy:&#10;&#9;&#9;&#9;data = Alloy.readlines()&#10;&#9;&#9;&#9;&#10;&#9;&#9;&#9;for line in data:&#10;&#9;&#9;&#9;&#9;&#10;&#9;&#9;&#9;&#9;instances, identifier = scrapeLine(line)&#10;&#9;&#9;&#9;&#9;#print(line)&#10;&#9;&#9;&#9;&#9;for instance in instances.replace(&quot; &quot;,&quot;&quot;).split(&quot;,&quot;):&#10;&#9;&#9;&#9;&#9;&#9;if(instance and identifier):&#10;&#9;&#9;&#9;&#9;&#9;&#9;#print(identifier + &quot; &quot; + instance)&#10;&#9;&#9;&#9;&#9;&#9;&#9;#print()&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#10;&#9;&#9;&#9;&#9;&#9;&#9;if(&quot;-&gt;&quot; in instance):&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;relation = instance.replace(&quot;-&gt;&quot;, &quot;,&quot;).split(&quot;,&quot;)&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;print(nmspc[relation[0] + &quot;!&quot; + str(index)] + &quot; &quot; + propertyDict[identifier] + &quot; &quot; + nmspc[relation[1] + &quot;!&quot; + str(index)])&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;o.rdflib_graph.add((nmspc[relation[0] + &quot;!&quot; + str(index)], propertyDict[identifier], nmspc[relation[1] + &quot;!&quot; + str(index)]))&#10;&#9;&#9;&#9;&#9;&#9;&#9;else:&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;print(nmspc[instance + &quot;!&quot; + str(index)] + &quot; &quot; + RDF.type + &quot; &quot; + classDict[identifier] )&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;o.rdflib_graph.add((nmspc[instance + &quot;!&quot; + str(index)], RDF.type, classDict[identifier]))&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#10;&#9;&#9;index = index + 1&#10;&#9;&#10;&#9;o.rdflib_graph.serialize(destination=str(os.path.join(outputDirectory, inputFile.split(&quot;/&quot;)[-1].split(&quot;.&quot;)[0] + &quot;.ttl&quot;)), format=&quot;turtle&quot;)&#10;"/>
        <parameter key="use_default_python" value="false"/>
        <parameter key="package_manager" value="specific python binaries"/>
        <parameter key="python_binary" value="/usr/bin/python"/>
      </operator>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <description align="center" color="yellow" colored="false" height="191" resized="true" width="247" x="852" y="363">Create a ttl file with the updated knowledge file</description>
      <description align="center" color="yellow" colored="false" height="103" resized="true" width="231" x="745" y="130">Requirements:&lt;br&gt;&lt;br&gt;ontospy:&lt;br/&gt;pip install ontospy</description>
      <description align="center" color="blue" colored="true" height="475" resized="true" width="505" x="229" y="316">Set the macros used by the scripts:&lt;br&gt;- inputFile: RDF/OWL/N3/TTL file of the schema to complete&lt;br&gt;- outputDirectory: Directory where to store the results&lt;br&gt;- inputDirectory: Directory where the .txt files are&lt;br&gt;the instances of the Alloy Analyser&lt;br/&gt;The index of the result is given by the alphabetical order&lt;br&gt;</description>
    </process>
  </operator>
</process>
