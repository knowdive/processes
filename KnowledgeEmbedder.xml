<?xml version="1.0" encoding="UTF-8"?><process version="9.6.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.4.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="logfile" value="/Users/mattiafumagalli/Desktop/prova.log"/>
    <parameter key="resultfile" value="/Users/mattiafumagalli/prova.res"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="set_macros" compatibility="9.6.000" expanded="true" height="68" name="Set pyKEEN macros" width="90" x="514" y="595">
        <list key="macros">
          <parameter key="FolderPath" value="/home/marco/Documents/Internship/resources/Vocabularies/schema_R"/>
          <parameter key="DatasetFinalName" value="example_R"/>
          <parameter key="ResultDirectory" value="/home/marco/Documents/Internship/resources/Vocabularies/schema_R/pyKEENres"/>
          <parameter key="execution_mode" value="Training_mode"/>
          <parameter key="kg_embedding_model_name" value="RESCAL"/>
          <parameter key="embedding_dim" value="100"/>
          <parameter key="normalization_of_entities" value="2"/>
          <parameter key="scoring_function" value="1"/>
          <parameter key="margin_loss" value="1"/>
          <parameter key="learning_rate" value="0.01"/>
          <parameter key="batch_size" value="32"/>
          <parameter key="num_epochs" value="1000"/>
          <parameter key="test_set_ratio" value="0.1"/>
          <parameter key="filter_negative_triples" value="True"/>
          <parameter key="random_seed" value="2"/>
          <parameter key="preferred_device" value="gpu"/>
          <parameter key="maximum_number_of_hpo_iters" value="5"/>
        </list>
      </operator>
      <operator activated="true" class="read_csv" compatibility="9.6.000" expanded="true" height="68" name="Read Triples CSV" width="90" x="246" y="289">
        <parameter key="csv_file" value="/home/marco/Desktop/lov_schema.csv"/>
        <parameter key="column_separators" value=","/>
        <parameter key="trim_lines" value="false"/>
        <parameter key="use_quotes" value="true"/>
        <parameter key="quotes_character" value="&quot;"/>
        <parameter key="escape_character" value="\"/>
        <parameter key="skip_comments" value="false"/>
        <parameter key="comment_characters" value="#"/>
        <parameter key="starting_row" value="1"/>
        <parameter key="parse_numbers" value="true"/>
        <parameter key="decimal_character" value="."/>
        <parameter key="grouped_digits" value="false"/>
        <parameter key="grouping_character" value=","/>
        <parameter key="infinity_representation" value=""/>
        <parameter key="date_format" value=""/>
        <parameter key="first_row_as_names" value="true"/>
        <list key="annotations"/>
        <parameter key="time_zone" value="SYSTEM"/>
        <parameter key="locale" value="English (United States)"/>
        <parameter key="encoding" value="UTF-8"/>
        <parameter key="read_all_values_as_polynominal" value="false"/>
        <list key="data_set_meta_data_information">
          <parameter key="0" value="att1.true.integer.attribute"/>
          <parameter key="1" value="Subject.true.polynominal.attribute"/>
          <parameter key="2" value="Predicate.true.polynominal.attribute"/>
          <parameter key="3" value="Object.true.polynominal.attribute"/>
          <parameter key="4" value="SubjectTerm.true.polynominal.attribute"/>
          <parameter key="5" value="PredicateTerm.true.polynominal.attribute"/>
          <parameter key="6" value="ObjectTerm.true.polynominal.attribute"/>
          <parameter key="7" value="Domain.true.polynominal.attribute"/>
          <parameter key="8" value="Domain Version.true.polynominal.attribute"/>
        </list>
        <parameter key="read_not_matching_values_as_missings" value="true"/>
        <parameter key="datamanagement" value="double_array"/>
        <parameter key="data_management" value="auto"/>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="103" name="Parse input pyKEEN" width="90" x="514" y="238">
        <parameter key="script" value="# Import libraries&#10;import pandas as pd&#10;from random import random&#10;import os&#10;&#10;# Mandatory function for RapidMiner&#10;def rm_main(triples):&#10;&#10;&#9;# Create Directory if not already present&#10;&#9;if not os.path.isdir(&quot;%{ResultDirectory}/%{DatasetFinalName}&quot;):&#10;&#9;&#9;os.makedirs(&quot;%{ResultDirectory}/%{DatasetFinalName}&quot;)&#10;&#10;&#9;# Create output files&#10;&#9;with open(r&quot;%{FolderPath}/%{DatasetFinalName}.tsv&quot;, &quot;w+&quot;) as train:&#10;&#9;&#9;# Iterate over every triples row&#10;&#9;&#9;for index, row in triples.iterrows():&#10;&#9;&#9;&#9;train.write(str(row[&quot;Subject&quot;])+&quot;\t&quot;+str(row[&quot;Predicate&quot;])+&quot;\t&quot;+str(row[&quot;Object&quot;])+&quot;\n&quot;) &#9;&#10;&#9;&#9;&#9;&#10;&#9;return "/>
        <parameter key="use_default_python" value="false"/>
        <parameter key="package_manager" value="specific python binaries"/>
        <parameter key="venvw_environment" value="/home/marco/venv/bin/python3"/>
        <parameter key="python_binary" value="/home/marco/venv/bin/python3"/>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="103" name="pyKEEN" width="90" x="648" y="238">
        <parameter key="script" value="# Import libraries&#10;import pykeen&#10;&#10;def rm_main():&#10;&#10;&#9;config = dict(&#10;&#9;    training_set_path           = '%{FolderPath}/%{DatasetFinalName}.tsv',&#10;&#9;    execution_mode              = '%{execution_mode}',&#10;&#9;    kg_embedding_model_name     = '%{kg_embedding_model_name}',&#10;&#9;    embedding_dim               = %{embedding_dim},&#10;&#9;    normalization_of_entities   = %{normalization_of_entities},  # corresponds to L2&#10;&#9;    scoring_function            = %{scoring_function},  # corresponds to L1&#10;&#9;    margin_loss                 = %{margin_loss},&#10;&#9;    learning_rate               = %{learning_rate},&#10;&#9;    batch_size                  = %{batch_size},&#10;&#9;    num_epochs                  = %{num_epochs},&#10;&#9;    test_set_ratio              = %{test_set_ratio},&#10;&#9;    filter_negative_triples     = %{filter_negative_triples},&#10;&#9;    random_seed                 = %{random_seed},&#10;&#9;    preferred_device            = '%{preferred_device}',&#10;&#9;    maximum_number_of_hpo_iters = %{maximum_number_of_hpo_iters},&#10;&#9;)&#10;&#10;&#9;results = pykeen.run(&#10;&#9;    config=config,&#10;&#9;    output_directory=&quot;%{ResultDirectory}&quot;,&#10;&#9;)&#10;&#10;&#9;# Create output files&#10;&#9;with open(r&quot;%{ResultDirectory}/%{DatasetFinalName}_trained_model.txt&quot;, &quot;w+&quot;) as res:&#10;&#9;&#9;res.write(str(results.trained_model)+&quot;\n&quot;)&#10;&#10;&#9;# Create output files&#10;&#9;with  open(r&quot;%{ResultDirectory}/%{DatasetFinalName}_losses.txt&quot;, &quot;w+&quot;) as res:&#10;&#9;&#9;res.write(str(results.losses)+&quot;\n&quot;) &#9;&#10;&#10;&#9;# Create output files&#10;&#9;with open(r&quot;%{ResultDirectory}/%{DatasetFinalName}_evaluation_summary.txt&quot;, &quot;w+&quot;) as res:&#10;&#9;&#9;res.write(str(results.evaluation_summary)+&quot;\n&quot;) &#9;"/>
        <parameter key="use_default_python" value="false"/>
        <parameter key="package_manager" value="specific python binaries"/>
        <parameter key="python_binary" value="/home/marco/venv/bin/python3"/>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.2.000" expanded="true" height="103" name="Parse output pyKEEN" width="90" x="782" y="238">
        <parameter key="script" value="# Import libraries&#10;import pandas as pd&#10;import json&#10;import numpy as np&#10;&#10;&#10;# Mandatory function for RapidMiner&#10;def rm_main():&#10;&#9;# Directory with the results of the Embedder&#10;&#9;output_directory=&quot;%{ResultDirectory}&quot;&#10;&#9;&#10;&#9;# Retrieve Entities Embedding from json file&#10;&#9;with open(output_directory+'/entities_to_embeddings.json') as entitiesE:&#10;&#9;&#9;entitiesEJSON = json.load(entitiesE)&#10;&#10;&#9;# Set the DataFrame that will contain the EuclideanNorm of evry combination of entities&#10;&#9;entitiesDF = pd.DataFrame({&quot;Entities|Entities&quot;: list(entitiesEJSON.keys())})&#10;&#9;entitiesDF[&quot;Entities|Entities&quot;] = range(0, len(entitiesEJSON.keys()))&#10;&#9;# Initiate it at 0.0 for every entry&#10;&#9;for i in range(0, len(entitiesEJSON.keys())):&#10;&#9;&#9;entitiesDF[i] = 0.0&#10;&#10;&#9;# Iterate over every cell of the DataFrame&#10;&#9;for i in range(0, len(entitiesEJSON.keys())):&#10;&#9;&#9;for j in range(0, len(entitiesEJSON.keys())):&#10;&#9;&#9;&#9;# Work only with elements not on the diagonal and not already checked &#10;&#9;&#9;&#9;if(i != j and entitiesDF.iat[i,j+1] == 0.0):&#10;&#9;&#9;&#9;&#9;# Transform the embeddings into a numpy array&#10;&#9;&#9;&#9;&#9;arrayI = np.array(entitiesEJSON[list(entitiesEJSON.keys())[i]])&#10;&#9;&#9;&#9;&#9;arrayJ = np.array(entitiesEJSON[list(entitiesEJSON.keys())[j]])&#10;&#9;&#9;&#9;&#9;# Compute the Euclidean norm between these 2 arrays&#10;&#9;&#9;&#9;&#9;norm = np.linalg.norm(arrayI - arrayJ)&#10;&#9;&#9;&#9;&#9;# Update both the combinations with the norm&#10;&#9;&#9;&#9;&#9;entitiesDF.iat[i,j+1] = str(norm)&#10;&#9;&#9;&#9;&#9;entitiesDF.iat[j,i+1] = str(norm)&#10;&#10;&#9;# Store the DataFrame as a csv file&#10;&#9;entitiesDF.to_csv(output_directory+'/entitiesMatrix.csv', index=False)&#10;&#10;&#10;&#9;# Retrieve Entities ID from json file&#10;&#9;with open(output_directory+'/entity_to_id.json') as entitiesID:&#10;&#9;&#9;entitiesIDJSON = json.load(entitiesID)&#10;&#9;&#9;entitiesIDJSON = list(entitiesIDJSON.keys())&#10;&#10;&#10;&#9;# Store top 10 closest Entities as a Json file Object&#10;&#9;with open(output_directory+'/entitiesList.json', 'w+') as entitiesL:&#10;&#9;&#9;# Start the Json object&#10;&#9;&#9;entitiesL.write(&quot;{\n&quot;)&#10;&#10;&#9;&#9;# Iterate over each Entity&#10;&#9;&#9;for i in range(0, len(entitiesDF.columns)-1):&#10;&#9;&#9;&#9;# If it's the first, skip the initial comma, for a correct Json formatting&#10;&#9;&#9;&#9;if(i):&#10;&#9;&#9;&#9;&#9;entitiesL.write(&quot;,&quot;)&#10;&#10;&#9;&#9;&#9;# Start Entity entry list&#10;&#9;&#9;&#9;entitiesL.write(&quot;\&quot;&quot;+entitiesIDJSON[i]+&quot;\&quot;:[\n&quot;)&#10;&#9;&#9;&#9;# Order the Entities DataFrame by that Entity&#10;&#9;&#9;&#9;entitiesDF.sort_values(by=[i], inplace=True)&#10;&#9;&#9;&#9;# Iterate over the top 10 closest Entities&#10;&#9;&#9;&#9;for j in range(1, 11):&#10;&#9;&#9;&#9;&#9;# If it's the first, skip the initial comma, for a correct Json formatting&#10;&#9;&#9;&#9;&#9;if(j!=1):&#10;&#9;&#9;&#9;&#9;&#9;entitiesL.write(&quot;,&quot;)&#10;&#9;&#9;&#9;&#9;# Add the close Entity together with its distance norm&#10;&#9;&#9;&#9;&#9;entitiesL.write(str(&quot;[\&quot;&quot; + str(entitiesIDJSON[entitiesDF.iloc[j,0]]) + &quot;\&quot;,&quot; +  str(entitiesDF.iloc[j,i+1]) + &quot;]\n&quot;).encode('utf-8').decode(&quot;utf-8&quot;))&#10;&#9;&#9;&#9;# End that Entity list&#10;&#9;&#9;&#9;entitiesL.write(&quot;]\n&quot;)&#10;&#10;&#9;&#9;# End the Json object&#10;&#9;&#9;entitiesL.write(&quot;}&quot;)&#10;&#10;&#10;&#9;# Retrieve Relations Embedding from json file&#10;&#9;with open(output_directory+'/relations_to_embeddings.json') as relationsE:&#10;&#9;&#9;relationsEJSON = json.load(relationsE)&#10;&#9;&#10;&#9;# Set the DataFrame that will contain the EuclideanNorm of every combination of relations&#10;&#9;relationsDF = pd.DataFrame({&quot;Relations|Relations&quot;:  list(relationsEJSON.keys())})&#10;&#9;# Initiate it at 0.0 for every entry&#10;&#9;for relKey in relationsEJSON.keys():&#10;&#9;&#9;relationsDF[relKey] = 0.0&#10;&#10;&#9;# Iterate over every cell of the DataFrame&#10;&#9;for i in range(0, len(relationsEJSON.keys())):&#10;&#9;&#9;for j in range(0, len(relationsEJSON.keys())):&#10;&#9;&#9;&#9;# Work only with elements not on the diagonal and not already checked&#10;&#9;&#9;&#9;if(i != j and relationsDF.iat[i,j+1] == 0.0):&#10;&#9;&#9;&#9;&#9;# Transform the embeddings into a numpy array&#10;&#9;&#9;&#9;&#9;arrayI = np.array(relationsEJSON[list(relationsEJSON.keys())[i]])&#10;&#9;&#9;&#9;&#9;arrayJ = np.array(relationsEJSON[list(relationsEJSON.keys())[j]])&#10;&#9;&#9;&#9;&#9;# Compute the Euclidean norm between these 2 arrays&#10;&#9;&#9;&#9;&#9;norm = np.linalg.norm(arrayI - arrayJ)&#10;&#9;&#9;&#9;&#9;# Update both the combination with the norm&#10;&#9;&#9;&#9;&#9;relationsDF.iat[i,j+1] = norm&#10;&#9;&#9;&#9;&#9;relationsDF.iat[j,i+1] = norm&#10;&#10;&#9;# Store the DataFrame as a csv file&#10;&#9;relationsDF.to_csv(output_directory+'/relationsMatrix.csv')&#10;&#10;&#10;&#9;# Store top 5 closest Relations as a Json file Object&#10;&#9;with open(output_directory+'/relationsList.json', 'w+') as relationsL:&#10;&#9;&#9;# Start the Json object&#10;&#9;&#9;relationsL.write(&quot;{\n&quot;)&#10;&#10;&#9;&#9;# Iterate over every Relation&#10;&#9;&#9;i = 1&#10;&#9;&#9;for relation in relationsDF.columns[1:]:&#10;&#9;&#9;&#9;# If it's the first, skip the initial comma, for a correct Json formatting&#10;&#9;&#9;&#9;if(i!=1):&#10;&#9;&#9;&#9;&#9;relationsL.write(&quot;,&quot;)&#10;&#10;&#9;&#9;&#9;# Start Relation entry list&#10;&#9;&#9;&#9;relationsL.write(&quot;\&quot;&quot;+relation+&quot;\&quot;:[\n&quot;)&#10;&#9;&#9;&#9;# Order the Relation DataFrame by that Relation&#10;&#9;&#9;&#9;relationsDF.sort_values(by=[relation], inplace=True)&#10;&#9;&#9;&#9;for j in range(0, 5):&#10;&#9;&#9;&#9;&#9;# Iterate over the top 5 closest Relations&#10;&#9;&#9;&#9;&#9;if(j!=0):&#10;&#9;&#9;&#9;&#9;&#9;relationsL.write(&quot;,&quot;)&#10;&#9;&#9;&#9;&#9;# Add the close Relation together with its distance norm&#10;&#9;&#9;&#9;&#9;relationsL.write(str(&quot;[\&quot;&quot; + str(relationsDF.iloc[j,0]) + &quot;\&quot;,&quot; +  str(relationsDF.iloc[j,i]) + &quot;]\n&quot;).encode('utf-8').decode(&quot;utf-8&quot;))&#10;&#9;&#9;&#9;# End that Relation list&#10;&#9;&#9;&#9;relationsL.write(&quot;]\n&quot;)&#10;&#10;&#9;&#9;&#9;# Update the index&#10;&#9;&#9;&#9;i += 1&#10;&#10;&#9;&#9;# End the Json object&#10;&#9;&#9;relationsL.write(&quot;}&quot;)&#10;&#10;&#9;# Return the DataFrames to RapidMiner for visualization&#10;&#9;return entitiesDF, relationsDF"/>
        <parameter key="use_default_python" value="false"/>
        <parameter key="package_manager" value="specific python binaries"/>
        <parameter key="venvw_environment" value="/home/marco/venv/bin/python3"/>
        <parameter key="python_binary" value="/usr/bin/python3"/>
      </operator>
      <connect from_op="Read Triples CSV" from_port="output" to_op="Parse input pyKEEN" to_port="input 1"/>
      <connect from_op="Parse input pyKEEN" from_port="output 1" to_op="pyKEEN" to_port="input 1"/>
      <connect from_op="pyKEEN" from_port="output 1" to_op="Parse output pyKEEN" to_port="input 1"/>
      <connect from_op="Parse output pyKEEN" from_port="output 1" to_port="result 1"/>
      <connect from_op="Parse output pyKEEN" from_port="output 2" to_port="result 2"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <portSpacing port="sink_result 3" spacing="0"/>
      <description align="center" color="blue" colored="true" height="217" resized="true" width="466" x="444" y="175">pyKEEN Pipeline&lt;br&gt;</description>
      <description align="center" color="blue" colored="true" height="204" resized="true" width="360" x="79" y="179">Use the input csv generated by LiveSchema&lt;br&gt;Using the Import Configuration Wizard:&lt;br&gt;Remember to tick the Use Quotes = &amp;quot;&lt;br&gt;Remeber to unTick the Use Comments&lt;br&gt;Remember to tick the Replace errors with missing values</description>
      <description align="center" color="gray" colored="true" height="200" resized="true" width="623" x="272" y="483">pyKEEN (https://github.com/SmartDataAnalytics/PyKEEN)&lt;br&gt;Overview: https://pykeen.readthedocs.io/en/latest/overview.html&lt;br&gt;Information about the configuration can be found: https://pykeen.readthedocs.io/en/latest/cli/train_and_evaluate.html</description>
      <description align="center" color="gray" colored="true" height="83" resized="true" width="272" x="155" y="372">Also Read from Excel using the output of the KnowledgeParser works</description>
      <description align="center" color="yellow" colored="false" height="118" resized="true" width="301" x="521" y="26">Before using this module you first have to run on the terminal the following commands:&lt;br&gt;pip install pykeen&lt;br&gt;and&lt;br&gt;pip install numpy</description>
    </process>
  </operator>
</process>
